# Voice-Cloning-Model
OpeninAPP (Voice Cloning)


Voice cloning is the creation of an artificial simulation of a person’s voice. Today’s AI software methods are capable of generating synthetic speech that closely resembles a targeted human voice. In some cases, the difference between the real and fake voice is imperceptible to the average person.

Online AI text-to-voice software began with using computers to synthesize voice. Text-to-Speech (TTS) is a decades-old technology that converts text into synthetic speech, enabling voice to be used for computer-human interaction.




We will be using Tocotron and Bark model in this Project
Basically 
 Tacotron is an AI-powered speech synthesis system that can convert text to speech. Tacotron 2's neural network architecture synthesises speech directly from text. It functions based on the combination of convolutional neural network (CNN) and recurrent neural network (RNN).

Bark is a transformer-based text-to-audio model created by Suno. Bark can generate highly realistic, multilingual speech as well as other audio - including music, background noise and simple sound effects. The model can also produce nonverbal communications like laughing, sighing and crying.

Bark has many languages inside its library like English , Hindi, Japanese, Korean etc..
Tocotron is used for TTS and is highly efficient and robust for that model.







Model:
Rename.py
Features
Automatically detects WAV files in a specified folder
Supports both uppercase and lowercase file extensions (e.g., .WAV and .wav)
Renames files sequentially with a numerical prefix (e.g., 1.wav, 2.wav, etc.)

Dependencies
Python 3.x

A simple Python script to batch rename WAV files in a folder numerically, specifically designed to facilitate the management and organization of audio files generated by the Tacotron 2 text-to-speech system.




	File 2(trancribe.py)

Prerequisites
Python 3.6 or higher
PyTorch
torchaudio
transformers

Clone the repository:
git clone https://github.com/yourusername/Tacotron2-Wav2Vec-Transcription.git
markdown Copy code
Install the required packages:
pip install torch torchaudio transformers
markdown Copy code
odify the transcribe.py script to set the appropriate input and output paths.
Run the script:
python transcribe_wav2vec.py
csharp Copy code


A Python script that uses the Wav2Vec2 model to transcribe .wav files and generates a .txt file for training a Tacotron2 text-to-speech model.
Overview
This script transcribes audio files in the WAV format using the Wav2Vec2 model from the Hugging Face Transformers library. It processes each WAV file, generates its corresponding transcription, and saves the transcription along with the file path in a .txt file. This .txt file can then be used for training a Tacotron2 text-to-speech model.


Output
The output .txt file contains one line per transcribed WAV file, with the file path followed by a pipe character | and the transcription. The format is as follows:
/content/TTS-TT2/wavs/1.wav|transcription of the first file /content/TTS-TT2/wavs/2.wav|transcription of the second file ... /content/TTS-TT2/wavs/n.wav|transcription of the nth file



Model 3:(Preprocess.py)

Requirements
Python 3.6 or higher
Librosa
SoundFile
Installation
Clone this repository to your local machine.
git clone https://github.com/yourusername/tacotron2-audio-preprocessor.git
markdown Copy code
Install the required libraries:
pip install librosa soundfile
r Copy code
Usage
Update the input_path and output_path variables in the prepross.py script to point to your input folder containing the .wav files and the desired output folder for the processed files.
This repository contains a Python script (tacotron2_preprocessor.py) that preprocesses audio files for training a Tacotron 2 text-to-speech model. The script trims silence, normalizes the audio, and saves the processed files to a specified output folder. It's specifically designed to work with .wav files to help create a clean and consistent dataset for Tacotron 2 model training.


File 4: Metadata.py

Prerequisites
Before you begin, ensure you have the following installed on your machine:
Python 3.x
taglib library

To install the taglib library, run the following command:
pip install python-taglib



Usage
Download the audio_metadata_updater.py script from this repository.
Modify the input_folder and output_folder variables in the script to match the desired source and destination folders for your audio files. For example:


input_folder = "C:\\path\\to\\your\\input\\folder"
output_folder = "C:\\path\\to\\your\\output\\folder"
Run the script using the following command:
Copy code
python audio_metadata_updater.py
The script will process the WAV files in the input_folder, update their metadata, and save the updated files in the output_folder. The original files in the input_folder will remain unchanged.
Notes
This script is designed to work with WAV files only. Other audio formats may not be compatible.
Ensure you have read and write permissions for both the input_folder and output_folder.
The script assumes that the file names are in the format "1.wav", "2.wav", etc., and will update the metadata accordingly. If your files are named differently, you may need to modify the script to suit your specific naming convention.
License
This project is licensed under the terms of the MIT license. See the LICENSE file for details.





